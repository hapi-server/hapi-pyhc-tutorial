{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPrfD4g5W6Dh"
   },
   "source": [
    "# Class Notebooks\n",
    "\n",
    "* [HAPI_00.ipynb](HAPI_00.ipynb) - Introduction\n",
    "* [HAPI_01.ipynb](HAPI_01.ipynb) - Basics\n",
    "* [HAPI_02.ipynb](HAPI_02.ipynb) - Data structures\n",
    "* [HAPI_03.ipynb](HAPI_03.ipynb) - Plotting\n",
    "* **[HAPI_04.ipynb](HAPI_04.ipynb) - Problems (this Notebook)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "Use the rest of the class time to work on these problems. Each problem is expected to take at least one hour, so start with a problem that interests you.\n",
    "\n",
    "You are welcome to work on problems not given here. However, priority for questions will be given to students working on these problems.\n",
    "\n",
    "For in-person students, we encourage you to work with one or more neighbors on a problem.\n",
    "\n",
    "Several HAPI experts are available for questions on chat, and three of us will be on-site for in-person questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Metadata I."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Basic\n",
    "\n",
    "\n",
    "Starting with\n",
    "\n",
    "```python\n",
    "import pickle as pickle\n",
    "with open('data/availability.pkl', 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "\n",
    "print(datasets[0:3])\n",
    "# [{'id': 'ace', 'title': 'ACE', 'startDate': '1997-08-25T17:48:00.000Z', 'stopDate': '2022-07-04T23:48:00.000Z'}, {'id': 'active', 'title': 'Active', 'startDate': '1989-09-29T00:00:00.000Z', 'stopDate': '1991-10-04T08:00:00.000Z'}, {'id': 'aec', 'title': 'AE-C', 'startDate': '1973-12-17T08:01:00.000Z', 'stopDate': '1978-12-10T00:00:00.000Z'}]\n",
    "```\n",
    "\n",
    "use the information in `datasets` to create a table and plot as described in the following subsections. You should be able to do this without requesting additional information from the server.\n",
    "\n",
    "(The information in `datasets` was creating using `hapi()` [metadata calls](HAPI_02.ipynb#Metadata) to the SSCWeb HAPI server.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table\n",
    "\n",
    "Create a table showing the time interval of availability of ephemeris data from the SSCWeb HAPI server. The table should have the form\n",
    "\n",
    "    ace              1997-08-25T17:48:00.000Z  2022-07-04T23:48:00.000Z\n",
    "    active           1989-09-29T00:00:00.000Z  1991-10-04T08:00:00.000Z\n",
    "    aec              1973-12-17T08:01:00.000Z  1978-12-10T00:00:00.000Z\n",
    "    ... (243 more lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'ace', 'title': 'ACE', 'startDate': '1997-08-25T17:48:00.000Z', 'stopDate': '2022-07-04T23:48:00.000Z'}, {'id': 'active', 'title': 'Active', 'startDate': '1989-09-29T00:00:00.000Z', 'stopDate': '1991-10-04T08:00:00.000Z'}, {'id': 'aec', 'title': 'AE-C', 'startDate': '1973-12-17T08:01:00.000Z', 'stopDate': '1978-12-10T00:00:00.000Z'}]\n"
     ]
    }
   ],
   "source": [
    "import pickle as pickle\n",
    "with open('data/availability.pkl', 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "print(datasets[0:3])\n",
    "\n",
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot\n",
    "\n",
    "Create a plot showing the time interval of availability of ephemeris data from the SSCWeb HAPI server. The plot should look similar to the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/availability-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Solution\n",
    "\n",
    "Solutions will be posted here at the end of the class period.\n",
    "\n",
    "## Advanced\n",
    "\n",
    "Write a program that creates the information in the dictionary `datasets` by querying the SSCWeb HAPI server. That is, write a program that creates the content that is stored in `availability.pkl`. (Metadata queries were covered in [HAPI_02.ipynb#Metadata](HAPI_02.ipynb#Metadata).)\n",
    "\n",
    "### Solution\n",
    "\n",
    "Solutions will be posted here at the end of the class period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Metadata II.\n",
    "\n",
    "Starting with\n",
    "\n",
    "```python\n",
    "import pickle as pickle\n",
    "with open('data/availability.pkl', 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "\n",
    "start = \"2003-10-31T23:00:00Z\"\n",
    "stop = \"2003-10-31T23:59:00Z\"\n",
    "```\n",
    "\n",
    "create a table that indicates the [spacecraft region](https://sscweb.gsfc.nasa.gov/users_guide/ssc_reg_doc.shtml) on `2003-10-31T23:00:00Z` for `ace`, `akebono`, `apex`, and `aqua` from SSCWeb. Your table should have columns of `Spacecraft ID`, `Region`, and `Time`, corresponding to the first time value on or after `start` as shown below.\n",
    "\n",
    "(Please do not attempt to create a table for all spacecraft - the SSCWeb HAPI server was not designed to handle a class of 300+ and so possibly 10-50 simultaneous requests.)\n",
    "\n",
    "```\n",
    "--------------------------------------------------------------------------------\n",
    "S/C ID           Region        Time\n",
    "\n",
    "ace              Intpl_Med\t 2003-304T23:00:00Z\n",
    "akebono          D_Psphere\t 2003-304T23:00:00Z\n",
    "apex             D_Msphere\t 2003-304T23:00:00Z\n",
    "aqua             N_Psphere\t 2003-304T23:00:00Z\n",
    "--------------------------------------------------------------------------------\n",
    "```\n",
    "\n",
    "## Solution\n",
    "\n",
    "Solutions will be posted at the end of the class period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Data\n",
    "\n",
    "Many datasets from CDAWeb contain ephemeris (position) data for the associated satellite.\n",
    "\n",
    "Use https://hapi-server.org/servers/ or https://heliophysicsdata.gsfc.nasa.gov/ to\n",
    "\n",
    "1. find a CDAWeb dataset that contains the ephemeris of a satellite, and\n",
    "2. find a SSCWeb dataset that contians the ephemeris of the same satellite.\n",
    "\n",
    "Then\n",
    "\n",
    "3. write a program to download the data, and  \n",
    "4. create a plot that compares the data.\n",
    "\n",
    "## Solution\n",
    "\n",
    "A sample solution will be posted at the end of the class period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Interpolating Time\n",
    "\n",
    "For analysis, it is often useful to place two datasets that have different timestamps on the same time grid. \n",
    "\n",
    "There are many ways to do this, for example,\n",
    "\n",
    "* Convert the timestamps in the NumPy `ndarray` returned by `hapi()` into integers, create a 1-D array of time integers to interpolate on to, and then either write your own interpolation function (not recommended) or use an interpolation function in [NumPy](https://numpy.org/doc/stable/reference/generated/numpy.interp.html) or [SciPy](https://docs.scipy.org/doc/scipy/reference/interpolate.html). An example of converting HAPI timestamps to `datetime` objects was given in [HAPI_02.ipynb#Time-Representation](HAPI_02.ipynb#Time-Representation); one can use [`datetime` methods](https://docs.python.org/3/library/datetime.html) to convert `datetime` objects into integers.\n",
    "\n",
    "\n",
    "* Place data in a Pandas `DataFrame` and use its interpolation methods (an example of placing data into a Pandas `DataFrame` was given in [HAPI_02.ipynb#Convert-to-Pandas-DataFrame](HAPI_02.ipynb#Convert-to-Pandas-DataFrame)).\n",
    "\n",
    "\n",
    "* In the [SpacePy](https://github.com/heliophysicsPy/summer-school/blob/main/spacepy-tutorial/SpacePy%20-%20MMS%20Ephemeris.md) tutorial (search on `tb.inter`) on Day 2, you used the [`interpol`](https://spacepy.github.io/autosummary/spacepy.toolbox.interpol.html#spacepy.toolbox.interpol) function in [`spacepy.toolbox`](https://spacepy.github.io/toolbox.html) to perform interpolation.\n",
    "\n",
    "Starting with the following program that reads datasets from two different data servers, use any library (or your own code) to\n",
    "\n",
    "1. write a program that interpolates `data2` on to the time grid of `data0` and\n",
    "\n",
    "2. create a table or plot that allows one to visually compare the interpolated values with the given values.\n",
    "\n",
    "Optionally,\n",
    "\n",
    "3. Write a program that averages `data0` into 1-hour time bins and compares the result with the contents of `data2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data0 = \n",
      "[(b'1998-02-04T00:00:31.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T00:01:35.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T00:02:39.000Z', -1.00000000e+31) ...\n",
      " (b'1998-02-05T23:57:19.000Z',  1.44819002e+01)\n",
      " (b'1998-02-05T23:58:23.000Z',  1.49483004e+01)\n",
      " (b'1998-02-05T23:59:27.000Z',  1.35783005e+01)]\n",
      "\n",
      "data2 = \n",
      "[(b'1998-02-04T00:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T01:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T02:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T03:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T04:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T05:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T06:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T07:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T08:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T09:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T10:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T11:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T12:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T13:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T14:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T15:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T16:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T17:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T18:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T19:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T20:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T21:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T22:00:00.000Z', -1.00000000e+31)\n",
      " (b'1998-02-04T23:00:00.000Z',  1.50185003e+01)\n",
      " (b'1998-02-05T00:00:00.000Z',  1.66550999e+01)\n",
      " (b'1998-02-05T01:00:00.000Z',  2.06009998e+01)\n",
      " (b'1998-02-05T02:00:00.000Z',  1.86788998e+01)\n",
      " (b'1998-02-05T03:00:00.000Z',  1.84808006e+01)\n",
      " (b'1998-02-05T04:00:00.000Z',  2.83150997e+01)\n",
      " (b'1998-02-05T05:00:00.000Z',  2.29591007e+01)\n",
      " (b'1998-02-05T06:00:00.000Z',  2.67126999e+01)\n",
      " (b'1998-02-05T07:00:00.000Z',  2.87502995e+01)\n",
      " (b'1998-02-05T08:00:00.000Z',  3.11555996e+01)\n",
      " (b'1998-02-05T09:00:00.000Z',  2.98451004e+01)\n",
      " (b'1998-02-05T10:00:00.000Z',  2.96215000e+01)\n",
      " (b'1998-02-05T11:00:00.000Z',  3.19601002e+01)\n",
      " (b'1998-02-05T12:00:00.000Z',  2.88362999e+01)\n",
      " (b'1998-02-05T13:00:00.000Z',  2.34172993e+01)\n",
      " (b'1998-02-05T14:00:00.000Z',  2.58817997e+01)\n",
      " (b'1998-02-05T15:00:00.000Z',  2.50207005e+01)\n",
      " (b'1998-02-05T16:00:00.000Z',  2.76191998e+01)\n",
      " (b'1998-02-05T17:00:00.000Z',  2.56742001e+01)\n",
      " (b'1998-02-05T18:00:00.000Z',  2.56151009e+01)\n",
      " (b'1998-02-05T19:00:00.000Z',  2.00079994e+01)\n",
      " (b'1998-02-05T20:00:00.000Z',  1.49785995e+01)\n",
      " (b'1998-02-05T21:00:00.000Z',  1.20008001e+01)\n",
      " (b'1998-02-05T22:00:00.000Z',  1.34287004e+01)\n",
      " (b'1998-02-05T23:00:00.000Z',  1.04862003e+01)]\n"
     ]
    }
   ],
   "source": [
    "from hapiclient import hapi, hapitime2datetime\n",
    "\n",
    "server     = 'https://cdaweb.gsfc.nasa.gov/hapi'\n",
    "dataset    = 'AC_H0_SWE'\n",
    "parameters = 'Np'\n",
    "start      = '1998-02-04'\n",
    "stop       = '1998-02-06'\n",
    "\n",
    "data0, meta0 = hapi(server, dataset, parameters, start, stop)\n",
    "print('data0 = ')\n",
    "print(data0)\n",
    "\n",
    "server     = 'https://cdaweb.gsfc.nasa.gov/hapi'\n",
    "dataset    = 'AC_H2_SWE'\n",
    "parameters = 'Np'\n",
    "start      = '1998-02-04'\n",
    "stop       = '1998-02-06'\n",
    "\n",
    "data2, meta2 = hapi(server, dataset, parameters, start, stop)\n",
    "print('\\ndata2 = ')\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Solution\n",
    "\n",
    "A sample solution will be posted at the end of the class period.\n",
    "\n",
    "# Coordinate Transform\n",
    "\n",
    "Starting with the following program,\n",
    "\n",
    "1. Print out the `GSE` and `GSM` values reported by SSCWeb.\n",
    "2. Use SpacePy to convert the `GSE` values to `GSM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacepy.coordinates as sc\n",
    "from spacepy.time import Ticktock\n",
    "\n",
    "from hapiclient import hapi, hapitime2datetime\n",
    "\n",
    "server     = 'https://hapi-server.org/servers/SSCWeb/hapi'\n",
    "dataset    = 'swarma'\n",
    "parameters = 'X_GSE,Y_GSE,Z_GSE,X_GSM,Y_GSM,Z_GSM'\n",
    "start      = '2013-11-26T00:00:00Z'\n",
    "stop       = '2013-11-26T00:01:00Z'\n",
    "\n",
    "opts       = {'logging': True, 'usecache': True, 'cachedir': './hapicache'}\n",
    "\n",
    "data, meta = hapi(server, dataset, parameters, start, stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "A sample solution will be posted at the end of the class period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SunPy Data Fusion\n",
    "\n",
    "In the last part of the [SunPy Tutorial](https://github.com/heliophysicsPy/summer-school/blob/main/sunpy-tutorial/05-multi-observer-application.ipynb), you plotted solar images on 2021-04-24. \n",
    "\n",
    "Solar wind plasma typically ~4 days to propagate from the solar surface to Earth. \n",
    "\n",
    "Find and plot data from at least one spacecraft from `2021-04-24` to `2021-04-30`. Be prepared to answer questions about your interpretation of any features in the time series.\n",
    "\n",
    "## Solution\n",
    "\n",
    "A sample solution will be posted at the end of the class period."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hapi_demo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "git": {
   "suppress_output": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
