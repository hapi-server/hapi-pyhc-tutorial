{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPrfD4g5W6Dh"
   },
   "source": [
    "# Overview of Notebooks\n",
    "\n",
    "* [HAPI_01.ipynb - Basics](HAPI_01.ipynb) \n",
    "* **[HAPI_02.ipynb - Data structures](HAPI_02.ipynb) (this Notebook)**\n",
    "* [HAPI_03.ipynb - Plotting](HAPI_03.ipynb)\n",
    "* [HAPI_04.ipynb - Problems](HAPI_04.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Matplotlib plots in page instead of opening a window\n",
    "%matplotlib inline \n",
    "# Have Matplotlib create vector (svg) instead of raster (png) images\n",
    "%config InlineBackend.figure_formats = ['svg'] \n",
    "\n",
    "# Misc. configuration\n",
    "import warnings\n",
    "# See https://github.com/boto/boto3/issues/454 for an explanation.\n",
    "warnings.simplefilter(\"ignore\", ResourceWarning) # removes spurious Notebook warns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8QD-RQXW6Dk"
   },
   "source": [
    "# Data Model\n",
    "\n",
    "A request for data of the form\n",
    "\n",
    "```python\n",
    "data, meta = hapi(server, dataset, parameters, start, stop)\n",
    "```\n",
    "\n",
    "returns the [Numpy N-D array](https://docs.scipy.org/doc/numpy-1.15.1/user/quickstart.html) `data` and a Python dictionary `meta` from a HAPI-compliant data server `server`. The structure of `meta` mirrors the structure of the metadata response from a HAPI server.\n",
    "\n",
    "The basic data structure returned by all HAPI servers is a CSV file in which the first column is a time stamp and subsequent columns are data measured or associated with that time stamp. The columns are mapped to one or more parameters (that may be multi-dimensional arrays) using the metadata associated with the request for CSV data.\n",
    "\n",
    "For more information on the HAPI server specification, see https://github.com/hapi-server/data-specification. Note that `hapiclient` requests HAPI Binary from a server if that feature is available; a HAPI compliant server is only required to serve HAPI CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XI4fUVj5W6Dl"
   },
   "source": [
    "# Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZFRo76fzW6Dl"
   },
   "outputs": [],
   "source": [
    "from hapiclient import hapi\n",
    "\n",
    "server     = 'http://hapi-server.org/servers/TestData2.0/hapi'\n",
    "dataset    = 'dataset1'\n",
    "parameters = 'scalar,vector'\n",
    "start      = '1970-01-01T00:00:00'\n",
    "stop       = '1970-01-01T00:00:10'\n",
    "\n",
    "data,meta = hapi(server,dataset,parameters,start,stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GITbtWjmW6Dl"
   },
   "source": [
    "`data` is a Numpy N-D array with named fields `Time`, `scalar`, and `vector`. The array has 10 elements (one for each time value) and each element is a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Satv6Bj1W6Dl",
    "outputId": "f80e3b72-675f-4bd5-e4e0-cc7de530d74e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(b'1970-01-01T00:00:00.000Z', 0.        , [ 0.        , -0.70710678, -1.        ]),\n",
       "       (b'1970-01-01T00:00:01.000Z', 0.00523596, [ 0.00523596, -0.7033947 , -0.99998629]),\n",
       "       (b'1970-01-01T00:00:02.000Z', 0.01047178, [ 0.01047178, -0.69966334, -0.99994517]),\n",
       "       (b'1970-01-01T00:00:03.000Z', 0.01570732, [ 0.01570732, -0.6959128 , -0.99987663]),\n",
       "       (b'1970-01-01T00:00:04.000Z', 0.02094242, [ 0.02094242, -0.69214317, -0.99978068]),\n",
       "       (b'1970-01-01T00:00:05.000Z', 0.02617695, [ 0.02617695, -0.68835458, -0.99965732]),\n",
       "       (b'1970-01-01T00:00:06.000Z', 0.03141076, [ 0.03141076, -0.68454711, -0.99950656]),\n",
       "       (b'1970-01-01T00:00:07.000Z', 0.03664371, [ 0.03664371, -0.68072087, -0.99932839]),\n",
       "       (b'1970-01-01T00:00:08.000Z', 0.04187565, [ 0.04187565, -0.67687597, -0.99912283]),\n",
       "       (b'1970-01-01T00:00:09.000Z', 0.04710645, [ 0.04710645, -0.67301251, -0.99888987])],\n",
       "      dtype=[('Time', 'S24'), ('scalar', '<f8'), ('vector', '<f8', (3,))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iqlq3FVKW6Dl"
   },
   "source": [
    "Access all values for parameter `Time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pU6_iEQlW6Dm",
    "outputId": "b118e3c4-890a-4684-b33f-7194d998bcf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'1970-01-01T00:00:00.000Z', b'1970-01-01T00:00:01.000Z',\n",
       "       b'1970-01-01T00:00:02.000Z', b'1970-01-01T00:00:03.000Z',\n",
       "       b'1970-01-01T00:00:04.000Z', b'1970-01-01T00:00:05.000Z',\n",
       "       b'1970-01-01T00:00:06.000Z', b'1970-01-01T00:00:07.000Z',\n",
       "       b'1970-01-01T00:00:08.000Z', b'1970-01-01T00:00:09.000Z'],\n",
       "      dtype='|S24')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8PS0mefW6Dm"
   },
   "source": [
    "Convert elements of `Time` to Python `datetime` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qUtza4Y_W6Dm",
    "outputId": "f0d274d5-1720-4990-8339-47e6ab12307d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.datetime(1970, 1, 1, 0, 0, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 1, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 2, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 3, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 4, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 5, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 6, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 7, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 8, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 9, tzinfo=<UTC>)], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hapiclient import hapitime2datetime\n",
    "dateTime = hapitime2datetime(data['Time'])\n",
    "dateTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiFuvnNYW6Dm"
   },
   "source": [
    "Access all values for parameter `vector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xd8v95D1W6Dm",
    "outputId": "c61913f4-a725-4c6e-d5ec-9b9459742bfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.70710678, -1.        ],\n",
       "       [ 0.00523596, -0.7033947 , -0.99998629],\n",
       "       [ 0.01047178, -0.69966334, -0.99994517],\n",
       "       [ 0.01570732, -0.6959128 , -0.99987663],\n",
       "       [ 0.02094242, -0.69214317, -0.99978068],\n",
       "       [ 0.02617695, -0.68835458, -0.99965732],\n",
       "       [ 0.03141076, -0.68454711, -0.99950656],\n",
       "       [ 0.03664371, -0.68072087, -0.99932839],\n",
       "       [ 0.04187565, -0.67687597, -0.99912283],\n",
       "       [ 0.04710645, -0.67301251, -0.99888987]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['vector']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpUxr1edW6Dn"
   },
   "source": [
    "Access first element (all parameters at first time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5V4f-x3W6Dn",
    "outputId": "a39503f4-bf7a-4e11-daa8-18aaaa01be0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'1970-01-01T00:00:00.000Z', 0., [ 0.        , -0.70710678, -1.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3u2x6OXW6Dn"
   },
   "source": [
    "Access value of `vector` at second timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SfRuSHmBW6Dn",
    "outputId": "86da4033-7813-4678-d20c-c59eacd80ecb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00523596, -0.7033947 , -0.99998629])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['vector'][1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKoRfY20W6Dn"
   },
   "source": [
    "Access value of second component of `vector` at second timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "piVwAegDW6Do",
    "outputId": "82faf274-c8d4-4211-bac8-e3a10ee770df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7033947028105039"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['vector'][1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow\">\n",
    "<h3>Problem 02a</h3>\n",
    "\n",
    "<p>Find the average radial distance of the moon in March of 2022. (To avoid 100+ users requesting data from the same data server, please use only this month; the data required to solve this problem is locally cached and <code>hapi</code> will use this cached data by default.)</p>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hapi(): Running hapi.py version 0.2.3\n",
      "hapi(): file directory = hapi-server.org_servers_SSCWeb_hapi\n",
      "hapi(): Reading moon_X_GEO_20220101T000000000_20220110T000000000.pkl\n",
      "hapi(): Reading moon_X_GEO_20220101T000000000_20220110T000000000.npy \n"
     ]
    }
   ],
   "source": [
    "from hapiclient import hapi\n",
    "\n",
    "server     = 'https://hapi-server.org/servers/SSCWeb/hapi'\n",
    "dataset    = 'moon'\n",
    "parameters = 'X_GEO'\n",
    "start      = '2022-01-01T00:00:00.000Z'\n",
    "stop       = '2022-01-10T00:00:00.000Z'\n",
    "\n",
    "data, meta = hapi(server, dataset, parameters, start, stop);\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "og71yLWGW6Do"
   },
   "source": [
    "# Time Representation\n",
    "\n",
    "A HAPI-compliant server represents time as an ISO 8601 string (with several constraints - see the [HAPI specification](https://github.com/hapi-server/data-specification/blob/master/hapi-dev/HAPI-data-access-spec-dev.md#representation-of-time)). `hapi.py` reads these into a NumPy array of [Python byte literals](https://stackoverflow.com/a/6273618). To convert byte literals to Python `datetime` objects, the function [`hapitime2datetime`](https://github.com/hapi-server/client-python/blob/master/hapiclient/hapi.py) can be used. Internally, this function uses `pandas.to_datetime` for parsing if possible. Otherwise it falls back to a manual method for parsing. The byte literals can also be converted to Astropy time objects as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bYIrxLUOW6Do"
   },
   "outputs": [],
   "source": [
    "from hapiclient import hapi\n",
    "from hapiclient import hapitime2datetime\n",
    "\n",
    "server     = 'http://hapi-server.org/servers/TestData2.0/hapi'\n",
    "dataset    = 'dataset1'\n",
    "parameters = 'scalar,vector'\n",
    "start      = '1970-01-01T00:00:00'\n",
    "stop       = '1970-01-01T00:00:10'\n",
    "\n",
    "data, meta = hapi(server, dataset, parameters, start, stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zqLUxv8XW6Do",
    "outputId": "a6577144-29c1-4c2e-d56d-986b707cea54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'1970-01-01T00:00:00.000Z', b'1970-01-01T00:00:01.000Z',\n",
       "       b'1970-01-01T00:00:02.000Z', b'1970-01-01T00:00:03.000Z',\n",
       "       b'1970-01-01T00:00:04.000Z', b'1970-01-01T00:00:05.000Z',\n",
       "       b'1970-01-01T00:00:06.000Z', b'1970-01-01T00:00:07.000Z',\n",
       "       b'1970-01-01T00:00:08.000Z', b'1970-01-01T00:00:09.000Z'],\n",
       "      dtype='|S24')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3W6cMLu1W6Do",
    "outputId": "c5991f3d-7c85-4872-dcd7-bcbac82209ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.datetime(1970, 1, 1, 0, 0, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 1, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 2, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 3, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 4, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 5, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 6, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 7, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 8, tzinfo=<UTC>),\n",
       "       datetime.datetime(1970, 1, 1, 0, 0, 9, tzinfo=<UTC>)], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapitime2datetime(data['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crdhE76LW6Dr"
   },
   "source": [
    "# Convert to Pandas DataFrame\n",
    "\n",
    "As HAPI data are NumPy arrays, conversion to Pandas DataFrames uses the existing `pandas.DataFrame` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "sZdqFSvCW6Dr",
    "outputId": "c0825261-f7d8-4b6c-c104-e6aa38fe25e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scalar</th>\n",
       "      <th>vector_x</th>\n",
       "      <th>vector_y</th>\n",
       "      <th>vector_z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00+00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01+00:00</th>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>-0.703395</td>\n",
       "      <td>-0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02+00:00</th>\n",
       "      <td>0.010472</td>\n",
       "      <td>0.010472</td>\n",
       "      <td>-0.699663</td>\n",
       "      <td>-0.999945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03+00:00</th>\n",
       "      <td>0.015707</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>-0.695913</td>\n",
       "      <td>-0.999877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04+00:00</th>\n",
       "      <td>0.020942</td>\n",
       "      <td>0.020942</td>\n",
       "      <td>-0.692143</td>\n",
       "      <td>-0.999781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:05+00:00</th>\n",
       "      <td>0.026177</td>\n",
       "      <td>0.026177</td>\n",
       "      <td>-0.688355</td>\n",
       "      <td>-0.999657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:06+00:00</th>\n",
       "      <td>0.031411</td>\n",
       "      <td>0.031411</td>\n",
       "      <td>-0.684547</td>\n",
       "      <td>-0.999507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:07+00:00</th>\n",
       "      <td>0.036644</td>\n",
       "      <td>0.036644</td>\n",
       "      <td>-0.680721</td>\n",
       "      <td>-0.999328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:08+00:00</th>\n",
       "      <td>0.041876</td>\n",
       "      <td>0.041876</td>\n",
       "      <td>-0.676876</td>\n",
       "      <td>-0.999123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:09+00:00</th>\n",
       "      <td>0.047106</td>\n",
       "      <td>0.047106</td>\n",
       "      <td>-0.673013</td>\n",
       "      <td>-0.998890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             scalar  vector_x  vector_y  vector_z\n",
       "Time                                                             \n",
       "1970-01-01 00:00:00+00:00  0.000000  0.000000 -0.707107 -1.000000\n",
       "1970-01-01 00:00:01+00:00  0.005236  0.005236 -0.703395 -0.999986\n",
       "1970-01-01 00:00:02+00:00  0.010472  0.010472 -0.699663 -0.999945\n",
       "1970-01-01 00:00:03+00:00  0.015707  0.015707 -0.695913 -0.999877\n",
       "1970-01-01 00:00:04+00:00  0.020942  0.020942 -0.692143 -0.999781\n",
       "1970-01-01 00:00:05+00:00  0.026177  0.026177 -0.688355 -0.999657\n",
       "1970-01-01 00:00:06+00:00  0.031411  0.031411 -0.684547 -0.999507\n",
       "1970-01-01 00:00:07+00:00  0.036644  0.036644 -0.680721 -0.999328\n",
       "1970-01-01 00:00:08+00:00  0.041876  0.041876 -0.676876 -0.999123\n",
       "1970-01-01 00:00:09+00:00  0.047106  0.047106 -0.673013 -0.998890"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data for use below\n",
    "from hapiclient import hapi\n",
    "from hapiclient import hapitime2datetime\n",
    "\n",
    "server     = 'http://hapi-server.org/servers/TestData2.0/hapi'\n",
    "dataset    = 'dataset1'\n",
    "parameters = 'scalar,vector'\n",
    "start      = '1970-01-01T00:00:00'\n",
    "stop       = '1970-01-01T00:00:10'\n",
    "\n",
    "data, meta = hapi(server,dataset,parameters,start,stop)\n",
    "\n",
    "import pandas\n",
    "\n",
    "df_Time = pandas.DataFrame(hapitime2datetime(data['Time']))\n",
    "df_scalar = pandas.DataFrame(data['scalar'])\n",
    "df_vector = pandas.DataFrame(data['vector'])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pandas.DataFrame()\n",
    "\n",
    "# Combine DataFrame\n",
    "df = pandas.concat([df_Time, df_scalar, df_vector], axis=1)\n",
    "\n",
    "# Name columns\n",
    "df.columns = ['Time', 'scalar','vector_x', 'vector_y', 'vector_z']\n",
    "\n",
    "# Set Time to be index\n",
    "df.set_index('Time', inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow\">\n",
    "<h3>Problem 02b</h3>\n",
    "\n",
    "<p>1. Find the mean and standard deviation of each column using <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\"><code>DataFrame</code></a> methods.</p>\n",
    "<p>2. Find the time that scalar is a maximum using <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\"><code>DataFrame</code></a> methods.</p>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4odZYcPW6Dr"
   },
   "source": [
    "# Convert to NDCube\n",
    "\n",
    "HAPI's NumPy data arrays can be converted to NDCubes (used by AstroPy) using the `ndcube.NDCube` function.\n",
    "\n",
    "We also set a WCS array, and create appropraite timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UGU9nYBQW6Ds"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ndcube\n",
      "  Downloading ndcube-2.0.1-py3-none-any.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 26.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: astropy>=4.2 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from ndcube) (5.0.1)\n",
      "Collecting gwcs>=0.15\n",
      "  Downloading gwcs-0.18.1-py3-none-any.whl (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 70.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>1.17 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from ndcube) (1.22.2)\n",
      "Requirement already satisfied: packaging>=19.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from astropy>=4.2->ndcube) (21.3)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from astropy>=4.2->ndcube) (5.4.1)\n",
      "Requirement already satisfied: pyerfa>=2.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from astropy>=4.2->ndcube) (2.0.0.1)\n",
      "Requirement already satisfied: scipy in /srv/conda/envs/notebook/lib/python3.9/site-packages (from gwcs>=0.15->ndcube) (1.8.0)\n",
      "Collecting asdf-wcs-schemas\n",
      "  Downloading asdf_wcs_schemas-0.1.1.tar.gz (22 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting asdf-astropy>=0.2.0\n",
      "  Downloading asdf_astropy-0.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting asdf>=2.8.1\n",
      "  Downloading asdf-2.11.0-py3-none-any.whl (402 kB)\n",
      "\u001b[K     |████████████████████████████████| 402 kB 81.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jsonschema>=4.0.1 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from asdf>=2.8.1->gwcs>=0.15->ndcube) (4.4.0)\n",
      "Collecting semantic-version>=2.8\n",
      "  Downloading semantic_version-2.9.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting asdf-standard>=1.0.1\n",
      "  Downloading asdf_standard-1.0.1-py3-none-any.whl (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting asdf-transform-schemas>=0.2.2\n",
      "  Downloading asdf_transform_schemas-0.2.2-py3-none-any.whl (191 kB)\n",
      "\u001b[K     |████████████████████████████████| 191 kB 81.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jmespath>=0.6.2 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from asdf>=2.8.1->gwcs>=0.15->ndcube) (0.10.0)\n",
      "Collecting asdf-coordinates-schemas\n",
      "  Downloading asdf_coordinates_schemas-0.1.0.tar.gz (11 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from jsonschema>=4.0.1->asdf>=2.8.1->gwcs>=0.15->ndcube) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from jsonschema>=4.0.1->asdf>=2.8.1->gwcs>=0.15->ndcube) (21.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from packaging>=19.0->astropy>=4.2->ndcube) (3.0.7)\n",
      "Building wheels for collected packages: asdf-coordinates-schemas, asdf-wcs-schemas\n",
      "  Building wheel for asdf-coordinates-schemas (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for asdf-coordinates-schemas: filename=asdf_coordinates_schemas-0.1.0-py3-none-any.whl size=19013 sha256=18a0bd0b338befce88fabeee349ea304ca59645006004b0cc080b800931d202d\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/d2/ec/e5/fa0a97eac37491832995f130264c88aa8e1033689e4cb5211f\n",
      "  Building wheel for asdf-wcs-schemas (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for asdf-wcs-schemas: filename=asdf_wcs_schemas-0.1.1-py3-none-any.whl size=26608 sha256=31fab1c051c25417f7df9232343e3eb1c5f5bc74f8cced8559b0d163731afad5\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/39/de/77/432e1ddeb8056a8f97c31817a2813a3fd03695e50f9f60e000\n",
      "Successfully built asdf-coordinates-schemas asdf-wcs-schemas\n",
      "Installing collected packages: asdf-standard, semantic-version, asdf-transform-schemas, asdf, asdf-coordinates-schemas, asdf-wcs-schemas, asdf-astropy, gwcs, ndcube\n",
      "Successfully installed asdf-2.11.0 asdf-astropy-0.2.0 asdf-coordinates-schemas-0.1.0 asdf-standard-1.0.1 asdf-transform-schemas-0.2.2 asdf-wcs-schemas-0.1.1 gwcs-0.18.1 ndcube-2.0.1 semantic-version-2.9.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ndcube.ndcube.NDCube object at 0x7f7914be64f0>\n",
       "NDCube\n",
       "------\n",
       "Dimensions: [10.] pix\n",
       "Physical Types of Axes: [('time', 'time')]\n",
       "Unit: None\n",
       "Data Type: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hapiclient import hapi\n",
    "from hapiclient import hapitime2datetime\n",
    "\n",
    "server     = 'http://hapi-server.org/servers/TestData2.0/hapi'\n",
    "dataset    = 'dataset1'\n",
    "parameters = 'scalar,vector'\n",
    "start      = '1970-01-01T00:00:00'\n",
    "stop       = '1970-01-01T00:00:10'\n",
    "\n",
    "data, meta = hapi(server, dataset, parameters, start, stop)\n",
    "\n",
    "dateTimes = hapitime2datetime(data['Time'])\n",
    "\n",
    "from datetime import timezone\n",
    "times = [dt.replace(tzinfo=timezone.utc).timestamp() for dt in dateTimes]\n",
    "\n",
    "import astropy.wcs\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "\n",
    "!pip install ndcube\n",
    "import ndcube\n",
    "\n",
    "my_wcs = astropy.wcs.WCS({\"CTYPE1\": \"TIME\", \n",
    "                          \"CUNIT1\": \"s\", \n",
    "                          \"CDELT1\": 1, \n",
    "                          \"CRPIX1\": 0, \n",
    "                          \"CRVAL1\": 0, \n",
    "                          \"NAXIS1\": 10})\n",
    "\n",
    "#extra_coords = [(\"time\", 0, dateTimes)]\n",
    "# latest ndcube changed the extra_coords option\n",
    "#cube = ndcube.NDCube(data['scalar'], my_wcs, extra_coords=extra_coords)\n",
    "cube = ndcube.NDCube(data['scalar'], my_wcs)\n",
    "\n",
    "from astropy.time import Time\n",
    "t=Time(dateTimes)\n",
    "cube.extra_coords.add('time',0,t)\n",
    "\n",
    "cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVSBi11IW6Dp",
    "tags": []
   },
   "source": [
    "# Generating Data (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djw-QZiBW6Dq",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "For testing, it may be useful to create a simulated HAPI data respsonse in Python. A HAPI response of\n",
    "\n",
    "```\n",
    "1970-01-01T00:00:00.000Z, 1.,2.,3.\n",
    "1970-01-01T00:00:02.000Z, 4.,5.,6.\n",
    "```\n",
    "\n",
    "where the metadata indicates there is one parameter named `vector` with `size=[3]` and `type=double` could be created by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Re-c-cZWW6Dq",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "cadd684f-ba0b-41f7-bec5-63cdbae9b09d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(b'1970-01-01T00:00:00.000Z', [1., 2., 3.]),\n",
       "       (b'1970-01-01T00:00:01.000Z', [4., 5., 6.])],\n",
       "      dtype=[('Time', 'S24'), ('vector', '<f8', (3,))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.ndarray(shape=(2), dtype=[('Time', 'S24'), ('vector', '<f8', (3,))])\n",
    "\n",
    "# Populate: method 1\n",
    "data['Time'] = np.array([b'1970-01-01T00:00:00.000Z', b'1970-01-01T00:00:01.000Z'])\n",
    "data['vector'] = np.array([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
    "\n",
    "# Populate: method 2\n",
    "data[0] = (b'1970-01-01T00:00:00.000Z', [1.0,2.0,3.0])\n",
    "data[1] = (b'1970-01-01T00:00:01.000Z', [4.0,5.0,6.0])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc5GS_qgW6Dq",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "A HAPI response of\n",
    "\n",
    "```\n",
    "1970-01-01T00:00:00.000Z, 1.,2.,3.,4.,5.,6.,7.,8.,9.\n",
    "1970-01-01T00:00:02.000Z, 11.,12.,13.,14.,15.,16.,17.,18.,19.\n",
    "```\n",
    "where the metadata indicates there is one parameter named `matrix` with `size=[3,3]` and `type=double` could be created by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FtE0FYUtW6Dq",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "c53329fb-e6bc-4280-a17a-4cb08929e17a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(b'1970-01-01T00:00:00.000Z', [[ 1.,  2.,  3.], [ 4.,  5.,  6.], [ 7.,  8.,  9.]]),\n",
       "       (b'1970-01-01T00:00:01.000Z', [[11., 12., 13.], [14., 15., 16.], [17., 18., 19.]])],\n",
       "      dtype=[('Time', 'S24'), ('matrix', '<f8', (3, 3))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Allocate\n",
    "data = np.ndarray(shape=(2), dtype=[('Time', 'S24'), ('matrix', '<f8', (3,3,))])\n",
    "\n",
    "# Populate\n",
    "data['Time'] = np.array([b'1970-01-01T00:00:00.000Z', b'1970-01-01T00:00:01.000Z'])\n",
    "data['matrix'] = np.array( [ [[1.0,2.0,3.0],[4.0,5.0,6.0],[7.0,8.0,9.0]], [[11.0,12.0,13.0],[14.0,15.0,16.0],[17.0,18.0,19.0]]] )\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vARSr3WEW6Dq",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Multiple parameters, e.g. a response with both the vector and matrix parameters considered above\n",
    "\n",
    "```\n",
    "1970-01-01T00:00:00.000Z, 1.,2.,3.,  1.,2.,3.,4.,5.,6.,7.,8.,9.\n",
    "1970-01-01T00:00:02.000Z, 4.,5.,6., 11.,12.,13.,14.,15.,16.,17.,18.,19.\n",
    "```\n",
    "\n",
    "can be created by populating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_i_qXFcW6Dr",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "51c6ef08-eaaf-4cc1-c5ec-cf3fdaec1607",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(b'1970-01-01T00:00:00.000Z', [1., 2., 3.], [[ 1.,  2.,  3.], [ 4.,  5.,  6.], [ 7.,  8.,  9.]]),\n",
       "       (b'1970-01-01T00:00:01.000Z', [4., 5., 6.], [[11., 12., 13.], [14., 15., 16.], [17., 18., 19.]])],\n",
       "      dtype=[('Time', 'S24'), ('vector', '<f8', (3,)), ('matrix', '<f8', (3, 3))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.ndarray(shape=(2), dtype=[('Time', 'S24'), ('vector', '<f8', (3,)), ('matrix', '<f8', (3,3,))])\n",
    "data['Time'] = np.array([b'1970-01-01T00:00:00.000Z', b'1970-01-01T00:00:01.000Z'])\n",
    "data['vector'] = np.array([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
    "data['matrix'] = np.array( [ [[1.0,2.0,3.0],[4.0,5.0,6.0],[7.0,8.0,9.0]], [[11.0,12.0,13.0],[14.0,15.0,16.0],[17.0,18.0,19.0]]] )\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Metadata\n",
    "\n",
    "The metadata returned by `hapi()` is a straightforward mapping of the JSON metadata from a HAPI server.  Earlier we showed the metadata for a dataset; now we look at (a) creating a list of all HAPI servers and (b) asking any specific HAPI server which datasets it has available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfNVaCD8W6Ds"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing all Servers\n",
    "\n",
    "HAPI has a query function to return all current HAPI servers, which is identical to the \n",
    "[Equivalent URL](https://github.com/hapi-server/data-specification/blob/master/servers.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://hapi-server.org/servers/SSCWeb/hapi',\n",
       " 'http://datashop.elasticbeanstalk.com/hapi',\n",
       " 'https://cdaweb.gsfc.nasa.gov/hapi',\n",
       " 'http://planet.physics.uiowa.edu/das/das2Server/hapi',\n",
       " 'https://iswa.gsfc.nasa.gov/IswaSystemWebApp/hapi',\n",
       " 'http://lasp.colorado.edu/lisird/hapi',\n",
       " 'http://hapi-server.org/servers/TestData2.0/hapi',\n",
       " 'http://amda.irap.omp.eu/service/hapi',\n",
       " 'https://vires.services/hapi']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hapiclient import hapi\n",
    "\n",
    "servers = hapi() # servers is an array of URLs\n",
    "display(servers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing all Datasets from a Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given server - in this example, CDAWeb - you can fetch the full list of dataset ids it serves. There is an [Equivalent URL: https://cdaweb.gsfc.nasa.gov/hapi/catalog](https://cdaweb.gsfc.nasa.gov/hapi/catalog) using the `catalog` endpoint (defined in the HAPI specification) that you can use as well.  Here, we only display the first five entries for example use, while a call to `display(meta)` will display them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'A1_K0_MPA'},\n",
       " {'id': 'A2_K0_MPA'},\n",
       " {'id': 'AC_AT_DEF'},\n",
       " {'id': 'AC_H0_MFI'},\n",
       " {'id': 'AC_H0_SWE'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hapiclient import hapi\n",
    "\n",
    "server = 'https://cdaweb.gsfc.nasa.gov/hapi'\n",
    "meta = hapi(server)\n",
    "\n",
    "display(meta['catalog'][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing all Parameters in a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataset's metadata is available as a query, without needing to fetch the actual data, using the `info` endpoint. For this example, there is an [Equivalent URL: https://cdaweb.gsfc.nasa.gov/hapi/info?id=AC_H0_MFI](https://cdaweb.gsfc.nasa.gov/hapi/info?id=AC_H0_MFI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HAPI': '2.0',\n",
       " 'status': {'code': 1200, 'message': 'OK'},\n",
       " 'parameters': [{'name': 'Time',\n",
       "   'type': 'isotime',\n",
       "   'units': 'UTC',\n",
       "   'length': 24,\n",
       "   'fill': None},\n",
       "  {'name': 'Magnitude',\n",
       "   'type': 'double',\n",
       "   'units': 'nT',\n",
       "   'fill': '-1.0E31',\n",
       "   'description': 'B-field magnitude'},\n",
       "  {'name': 'BGSEc',\n",
       "   'type': 'double',\n",
       "   'units': 'nT',\n",
       "   'fill': '-1.0E31',\n",
       "   'description': 'Magnetic Field Vector in GSE Cartesian coordinates (16 sec)',\n",
       "   'size': [3]},\n",
       "  {'name': 'BGSM',\n",
       "   'type': 'double',\n",
       "   'units': 'nT',\n",
       "   'fill': '-1.0E31',\n",
       "   'description': 'Magnetic field vector in GSM coordinates (16 sec)',\n",
       "   'size': [3]},\n",
       "  {'name': 'dBrms',\n",
       "   'type': 'double',\n",
       "   'units': 'nT',\n",
       "   'fill': '-1.0E31',\n",
       "   'description': 'RMS of Magnetic Field (16 sec period)'},\n",
       "  {'name': 'SC_pos_GSE',\n",
       "   'type': 'double',\n",
       "   'units': 'km',\n",
       "   'fill': '-1.0E31',\n",
       "   'description': 'ACE s/c position, 3 comp. in GSE coord.',\n",
       "   'size': [3]},\n",
       "  {'name': 'SC_pos_GSM',\n",
       "   'type': 'double',\n",
       "   'units': 'km',\n",
       "   'fill': '-1.0E31',\n",
       "   'description': 'ACE s/c position, 3 comp. in GSM coord.',\n",
       "   'size': [3]}],\n",
       " 'startDate': '1997-09-02T00:00:12Z',\n",
       " 'stopDate': '2022-01-03T23:59:58Z',\n",
       " 'resourceURL': 'https://cdaweb.gsfc.nasa.gov/misc/NotesA.html#AC_H0_MFI',\n",
       " 'contact': 'N. Ness @ Bartol Research Institute'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hapiclient import hapi\n",
    "\n",
    "server  = 'https://cdaweb.gsfc.nasa.gov/hapi'\n",
    "dataset = 'AC_H0_MFI'\n",
    "meta = hapi(server,dataset)\n",
    "display(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Parameter Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can likewise examine a subset of the full dataset (rather than all variables returnable) by adding the same 'parameters' call you would use in a query.\n",
    "[Equivalent URL: https://cdaweb.gsfc.nasa.gov/hapi/info?id=AC_H0_MFI&parameters=Magnitude,BGSEc](https://cdaweb.gsfc.nasa.gov/hapi/info?id=AC_H0_MFI&parameters=Magnitude,BGSEc)\n",
    "\n",
    "(Note that HAPI allows 'unlisted' non-standard internal keys that prefixed by `x_`.  Similar to the Python `_name` scheme, this is an advanced feature not covered in this tutorial.)\n",
    "\n",
    "Here we fetch just the `Magnitude` and `BGSEc` for the `AC_H0_MFI` dataset from `CDAWeb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HAPI': '2.0',\n",
       " 'status': {'code': 1200, 'message': 'OK'},\n",
       " 'parameters': [{'name': 'Time',\n",
       "   'type': 'isotime',\n",
       "   'units': 'UTC',\n",
       "   'length': 24,\n",
       "   'fill': None},\n",
       "  {'name': 'Magnitude',\n",
       "   'type': 'double',\n",
       "   'units': 'nT',\n",
       "   'fill': '-1.0E31',\n",
       "   'description': 'B-field magnitude'},\n",
       "  {'name': 'BGSEc',\n",
       "   'type': 'double',\n",
       "   'units': 'nT',\n",
       "   'fill': '-1.0E31',\n",
       "   'description': 'Magnetic Field Vector in GSE Cartesian coordinates (16 sec)',\n",
       "   'size': [3]}],\n",
       " 'startDate': '1997-09-02T00:00:12Z',\n",
       " 'stopDate': '2022-01-03T23:59:58Z',\n",
       " 'resourceURL': 'https://cdaweb.gsfc.nasa.gov/misc/NotesA.html#AC_H0_MFI',\n",
       " 'contact': 'N. Ness @ Bartol Research Institute',\n",
       " 'x_server': 'https://cdaweb.gsfc.nasa.gov/hapi',\n",
       " 'x_dataset': 'AC_H0_MFI'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hapiclient import hapi\n",
    "\n",
    "server     = 'https://cdaweb.gsfc.nasa.gov/hapi'\n",
    "dataset    = 'AC_H0_MFI'\n",
    "parameters = 'Magnitude,BGSEc'\n",
    "\n",
    "meta = hapi(server,dataset,parameters)\n",
    "\n",
    "display(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Next up, [plotting data](HAPI_03.ipynb)\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hapi_demo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "git": {
   "suppress_output": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
